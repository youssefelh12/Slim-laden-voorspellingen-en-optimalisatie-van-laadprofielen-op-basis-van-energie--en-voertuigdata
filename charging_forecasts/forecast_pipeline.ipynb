{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.preprocessing\n",
    "from sklearn.metrics import r2_score\n",
    "from pandas import read_csv\n",
    "from datetime import datetime\n",
    "from keras.layers import Dense,Dropout,SimpleRNN,LSTM\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hour</th>\n",
       "      <th>Chargers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-09-28 12:00:00</td>\n",
       "      <td>2.4090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-09-28 13:00:00</td>\n",
       "      <td>6.0426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-09-28 14:00:00</td>\n",
       "      <td>6.0271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-09-28 15:00:00</td>\n",
       "      <td>6.0016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-09-28 16:00:00</td>\n",
       "      <td>7.1028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Hour  Chargers\n",
       "0  2022-09-28 12:00:00    2.4090\n",
       "1  2022-09-28 13:00:00    6.0426\n",
       "2  2022-09-28 14:00:00    6.0271\n",
       "3  2022-09-28 15:00:00    6.0016\n",
       "4  2022-09-28 16:00:00    7.1028"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./hourly_predictions/hourly_charging_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing rows:\n",
      "                     Chargers\n",
      "2022-10-05 13:00:00       NaN\n",
      "2022-10-05 14:00:00       NaN\n",
      "2022-10-05 15:00:00       NaN\n",
      "2022-10-05 16:00:00       NaN\n",
      "2022-10-05 17:00:00       NaN\n",
      "...                       ...\n",
      "2023-09-06 14:00:00       NaN\n",
      "2023-09-06 15:00:00       NaN\n",
      "2023-09-06 16:00:00       NaN\n",
      "2024-03-31 02:00:00       NaN\n",
      "2024-05-22 17:00:00       NaN\n",
      "\n",
      "[1042 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# 1. Convert Hour to DateTime type\n",
    "df['Hour'] = pd.to_datetime(df['Hour'])\n",
    "\n",
    "# 2. Set Hour as the DataFrame index\n",
    "df = df.set_index('Hour')\n",
    "\n",
    "# 3. Reindex to every hour in the range from the min to max timestamps\n",
    "all_hours = pd.date_range(start=df.index.min(), end=df.index.max(), freq='H')\n",
    "df_reindexed = df.reindex(all_hours)\n",
    "\n",
    "# 4. Identify which rows are missing\n",
    "missing_rows = df_reindexed[df_reindexed['Chargers'].isnull()]\n",
    "print(\"Missing rows:\")\n",
    "print(missing_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chargers</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hour</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-09-28 12:00:00</th>\n",
       "      <td>2.4090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-28 13:00:00</th>\n",
       "      <td>6.0426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-28 14:00:00</th>\n",
       "      <td>6.0271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-28 15:00:00</th>\n",
       "      <td>6.0016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-28 16:00:00</th>\n",
       "      <td>7.1028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-19 08:00:00</th>\n",
       "      <td>45.9840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-19 09:00:00</th>\n",
       "      <td>106.6935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-19 10:00:00</th>\n",
       "      <td>101.6063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-19 11:00:00</th>\n",
       "      <td>84.9264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-19 12:00:00</th>\n",
       "      <td>51.2582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19959 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Chargers\n",
       "Hour                         \n",
       "2022-09-28 12:00:00    2.4090\n",
       "2022-09-28 13:00:00    6.0426\n",
       "2022-09-28 14:00:00    6.0271\n",
       "2022-09-28 15:00:00    6.0016\n",
       "2022-09-28 16:00:00    7.1028\n",
       "...                       ...\n",
       "2025-02-19 08:00:00   45.9840\n",
       "2025-02-19 09:00:00  106.6935\n",
       "2025-02-19 10:00:00  101.6063\n",
       "2025-02-19 11:00:00   84.9264\n",
       "2025-02-19 12:00:00   51.2582\n",
       "\n",
       "[19959 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a string key for month-day-hour, e.g. '09-06-03'\n",
    "df_reindexed['month_day_hour'] = df_reindexed.index.strftime('%m-%d-%H')\n",
    "\n",
    "# Compute the mean for each specific month/day/hour across all years\n",
    "mdh_mean = df_reindexed.groupby('month_day_hour')['Chargers'].transform('mean')\n",
    "\n",
    "# Fill missing values with that mean\n",
    "df['Chargers'] = df_reindexed['Chargers'].fillna(mdh_mean)\n",
    "\n",
    "# Clean up the extra grouping column\n",
    "df_reindexed.drop(columns=['month_day_hour'], inplace=True)\n",
    "\n",
    "df.isna().sum()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler saved → models\\chargers\\charger_scaler.joblib\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\enviroments\\Stage_project\\.venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 - 15s - 246ms/step - loss: 0.0145 - val_loss: 0.0453\n",
      "Epoch 2/50\n",
      "62/62 - 12s - 201ms/step - loss: 0.0100 - val_loss: 0.0322\n",
      "Epoch 3/50\n",
      "62/62 - 18s - 292ms/step - loss: 0.0084 - val_loss: 0.0281\n",
      "Epoch 4/50\n",
      "62/62 - 20s - 319ms/step - loss: 0.0073 - val_loss: 0.0232\n",
      "Epoch 5/50\n",
      "62/62 - 20s - 316ms/step - loss: 0.0067 - val_loss: 0.0244\n",
      "Epoch 6/50\n",
      "62/62 - 20s - 324ms/step - loss: 0.0062 - val_loss: 0.0240\n",
      "Epoch 7/50\n",
      "62/62 - 20s - 320ms/step - loss: 0.0058 - val_loss: 0.0241\n",
      "Epoch 8/50\n",
      "62/62 - 20s - 319ms/step - loss: 0.0054 - val_loss: 0.0254\n",
      "Epoch 9/50\n",
      "62/62 - 17s - 278ms/step - loss: 0.0051 - val_loss: 0.0252\n",
      "Epoch 10/50\n",
      "62/62 - 23s - 379ms/step - loss: 0.0048 - val_loss: 0.0234\n",
      "Epoch 11/50\n",
      "62/62 - 20s - 328ms/step - loss: 0.0046 - val_loss: 0.0266\n",
      "Epoch 12/50\n",
      "62/62 - 20s - 330ms/step - loss: 0.0044 - val_loss: 0.0247\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step\n",
      "TEST 24-step →  RMSE=0.181  MAE=0.109  R²=0.591\n",
      "Model saved → models\\chargers\\lstm_chargers.keras\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Multivariate, 24-step LSTM – trains with a 168-hour look-back,\n",
    "saves both the network and the fitted MinMaxScaler.\n",
    "\"\"\"\n",
    "\n",
    "import pathlib, math, holidays, joblib    # ← NEW: joblib\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# ───────────────────────── CONFIG ──────────────────────────\n",
    "TARGET_COL   = \"Chargers\"\n",
    "LOOK_BACK    = 72          # 7 days window (168 × 1 h)\n",
    "N_FORECAST   = 24             # predict 24 h ahead\n",
    "EPOCHS       = 50\n",
    "BATCH_SIZE   = 256\n",
    "PATIENCE     = 8\n",
    "MODEL_PATH   = pathlib.Path(\"./models/chargers/lstm_chargers.keras\")\n",
    "SCALER_PATH  = pathlib.Path(\"./models/chargers/charger_scaler.joblib\")  # ← NEW\n",
    "START_DATE   = \"2022-09-11\"\n",
    "END_DATE     = \"2025-02-19\"\n",
    "\n",
    "# ───────────────────────── DATA LOAD ───────────────────────\n",
    "df = df.loc[START_DATE:END_DATE].copy()      # replace with your loader\n",
    "\n",
    "# ─────────────────────── FEATURE ENGINEERING ───────────────\n",
    "be_holidays = set(holidays.country_holidays(\n",
    "                  \"BE\", years=[2022, 2023, 2024, 2025]).keys())\n",
    "\n",
    "def add_terugkomdag_feature(df):\n",
    "    # List of 'terugkomdagen' dates\n",
    "    terugkomdagen = [\n",
    "        datetime(2023, 9, 13), datetime(2023, 10, 26), datetime(2023, 11, 14), datetime(2023, 12, 20),\n",
    "        datetime(2024, 1, 12), datetime(2024, 2, 7), datetime(2024, 3, 14), datetime(2024, 4, 16),\n",
    "        datetime(2024, 5, 13), datetime(2024, 6, 7), datetime(2024, 3, 16), datetime(2024, 10, 22),\n",
    "        datetime(2024, 11, 28), datetime(2024, 12, 18), datetime(2025, 1, 10), datetime(2025, 2, 13),\n",
    "        datetime(2025, 3, 18), datetime(2025, 4, 22), datetime(2025, 5, 12), datetime(2025, 6, 6)\n",
    "    ]\n",
    "    df['is_terugkomdag'] = df.index.to_series().dt.date.isin([d.date() for d in terugkomdagen]).astype(int)\n",
    "\n",
    "    return df\n",
    "def add_cumulative_ev_phev_feature(df):\n",
    "    from datetime import datetime\n",
    "\n",
    "    # List of (date, cumulative_count) from your analysis\n",
    "    cumulative_data = {\n",
    "        datetime(2024, 6, 20): 35,\n",
    "        datetime(2024, 6, 25): 36,\n",
    "        datetime(2024, 9, 5): 38,\n",
    "        datetime(2024, 9, 12): 41,\n",
    "        datetime(2024, 9, 27): 42,\n",
    "        datetime(2024, 10, 15): 43,\n",
    "        datetime(2024, 10, 29): 45,\n",
    "        datetime(2024, 11, 5): 46,\n",
    "        datetime(2024, 11, 26): 47,\n",
    "        datetime(2025, 1, 9): 48,\n",
    "        datetime(2025, 1, 23): 49,\n",
    "        datetime(2025, 1, 28): 50,\n",
    "        datetime(2025, 2, 4): 51,\n",
    "    }\n",
    "\n",
    "    # Turn it into a Series and reindex to all dates in your dataset\n",
    "    ev_series = pd.Series(cumulative_data)\n",
    "    ev_series = ev_series.reindex(df.index.union(ev_series.index)).sort_index().ffill().fillna(0)\n",
    "\n",
    "    # Add it to your DataFrame\n",
    "    df[\"cumulative_ev_phev_count\"] = ev_series.reindex(df.index).astype(int)\n",
    "\n",
    "    return df\n",
    "\n",
    "add_terugkomdag_feature(df)\n",
    "add_cumulative_ev_phev_feature(df)\n",
    "\n",
    "df[\"hour\"]           = df.index.hour\n",
    "df[\"day_of_week\"]    = df.index.dayofweek\n",
    "df[\"month\"]          = df.index.month\n",
    "df[\"is_weekend\"]     = (df[\"day_of_week\"] >= 5).astype(int)\n",
    "df[\"is_festive\"]     = df.index.to_series().apply(\n",
    "                         lambda d: int(d.date() in be_holidays))\n",
    "\n",
    "df[\"working_hour\"]   = df[\"hour\"].between(8, 18).astype(int)\n",
    "df[\"is_summer\"]      = df[\"month\"].isin([6, 7, 8]).astype(int)\n",
    "df[\"is_winter\"]      = df[\"month\"].isin([12, 1, 2]).astype(int)\n",
    "df[\"is_morning_peak\"] = df[\"hour\"].between(7, 9).astype(int)\n",
    "df[\"is_evening_peak\"] = df[\"hour\"].between(17, 20).astype(int)\n",
    "df[\"hour_sin\"]       = np.sin(2*np.pi*df[\"hour\"]/24)\n",
    "df[\"hour_cos\"]       = np.cos(2*np.pi*df[\"hour\"]/24)\n",
    "df[\"dow_sin\"]        = np.sin(2*np.pi*df[\"day_of_week\"]/7)\n",
    "df[\"dow_cos\"]        = np.cos(2*np.pi*df[\"day_of_week\"]/7)\n",
    "\n",
    "FEATURE_COLS = [c for c in df.columns if c != TARGET_COL]\n",
    "\n",
    "# ─────────────── 1️⃣  CHRONOLOGICAL SPLIT  ────────────────\n",
    "train_size = int(len(df)*0.8)\n",
    "val_size   = int(len(df)*0.1)\n",
    "\n",
    "df_train = df.iloc[:train_size]\n",
    "df_val   = df.iloc[train_size:train_size+val_size]\n",
    "df_test  = df.iloc[train_size+val_size:]\n",
    "\n",
    "# ─────────────── 2️⃣  FIT & SAVE SCALER  ──────────────────\n",
    "scaler = MinMaxScaler()                                     # DOCS :contentReference[oaicite:2]{index=2}\n",
    "scaler.fit(df_train[[TARGET_COL] + FEATURE_COLS])           # fit **train only** :contentReference[oaicite:3]{index=3}\n",
    "joblib.dump(scaler, SCALER_PATH)                            # persist scaler :contentReference[oaicite:4]{index=4}\n",
    "print(\"Scaler saved →\", SCALER_PATH)\n",
    "\n",
    "def scale(frame):        # helper to apply the saved scaler\n",
    "    cols = [TARGET_COL] + FEATURE_COLS\n",
    "    return pd.DataFrame(scaler.transform(frame[cols]), columns=cols,\n",
    "                        index=frame.index)\n",
    "\n",
    "df_train_s, df_val_s, df_test_s = map(scale, (df_train, df_val, df_test))\n",
    "\n",
    "# ─────────────── 3️⃣  BUILD INPUT / LABEL WINDOWS ─────────\n",
    "def make_xy(frame, look_back, horizon):\n",
    "    data = frame[[TARGET_COL]+FEATURE_COLS].values\n",
    "    X, y = [], []\n",
    "    for i in range(look_back, len(data)-horizon+1):\n",
    "        X.append(data[i-look_back:i])\n",
    "        y.append(data[i:i+horizon, 0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X_train, y_train = make_xy(df_train_s, LOOK_BACK, N_FORECAST)\n",
    "X_val,   y_val   = make_xy(df_val_s,   LOOK_BACK, N_FORECAST)\n",
    "X_test,  y_test  = make_xy(df_test_s,  LOOK_BACK, N_FORECAST)\n",
    "\n",
    "# ─────────────── 4️⃣  DEFINE & TRAIN MODEL ────────────────\n",
    "model = Sequential([\n",
    "    LSTM(64, return_sequences=True, input_shape=(LOOK_BACK, X_train.shape[2])),\n",
    "    Dropout(0.2),\n",
    "    LSTM(64, return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    LSTM(64),\n",
    "    Dropout(0.2),\n",
    "    Dense(N_FORECAST)\n",
    "])\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "cb = EarlyStopping(patience=PATIENCE, restore_best_weights=True)  # :contentReference[oaicite:5]{index=5}\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          epochs=EPOCHS, batch_size=BATCH_SIZE,\n",
    "          validation_data=(X_val, y_val), callbacks=[cb], verbose=2)\n",
    "\n",
    "# ─────────────── 5️⃣  EVALUATE  ───────────────────────────\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "rmse = math.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae  = mean_absolute_error(y_test, y_pred)\n",
    "r2   = r2_score(y_test, y_pred)\n",
    "print(f\"TEST 24-step →  RMSE={rmse:.3f}  MAE={mae:.3f}  R²={r2:.3f}\")\n",
    "\n",
    "# ─────────────── 6️⃣  SAVE MODEL (.keras format) ──────────\n",
    "MODEL_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "model.save(MODEL_PATH)                                       # Keras v3 format :contentReference[oaicite:6]{index=6}\n",
    "print(\"Model saved →\", MODEL_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler saved → models\\chargers\\charger_scaler.joblib\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\enviroments\\Stage_project\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 - 2s - 33ms/step - loss: 0.0347 - val_loss: 0.0570\n",
      "Epoch 2/50\n",
      "62/62 - 1s - 12ms/step - loss: 0.0120 - val_loss: 0.0414\n",
      "Epoch 3/50\n",
      "62/62 - 1s - 10ms/step - loss: 0.0095 - val_loss: 0.0312\n",
      "Epoch 4/50\n",
      "62/62 - 1s - 10ms/step - loss: 0.0082 - val_loss: 0.0264\n",
      "Epoch 5/50\n",
      "62/62 - 1s - 10ms/step - loss: 0.0074 - val_loss: 0.0249\n",
      "Epoch 6/50\n",
      "62/62 - 1s - 10ms/step - loss: 0.0069 - val_loss: 0.0237\n",
      "Epoch 7/50\n",
      "62/62 - 1s - 10ms/step - loss: 0.0068 - val_loss: 0.0225\n",
      "Epoch 8/50\n",
      "62/62 - 1s - 10ms/step - loss: 0.0064 - val_loss: 0.0249\n",
      "Epoch 9/50\n",
      "62/62 - 1s - 9ms/step - loss: 0.0063 - val_loss: 0.0225\n",
      "Epoch 10/50\n",
      "62/62 - 1s - 10ms/step - loss: 0.0061 - val_loss: 0.0202\n",
      "Epoch 11/50\n",
      "62/62 - 1s - 10ms/step - loss: 0.0059 - val_loss: 0.0215\n",
      "Epoch 12/50\n",
      "62/62 - 1s - 10ms/step - loss: 0.0059 - val_loss: 0.0229\n",
      "Epoch 13/50\n",
      "62/62 - 1s - 10ms/step - loss: 0.0057 - val_loss: 0.0241\n",
      "Epoch 14/50\n",
      "62/62 - 1s - 10ms/step - loss: 0.0056 - val_loss: 0.0247\n",
      "Epoch 15/50\n",
      "62/62 - 1s - 12ms/step - loss: 0.0055 - val_loss: 0.0244\n",
      "Epoch 16/50\n",
      "62/62 - 1s - 11ms/step - loss: 0.0054 - val_loss: 0.0236\n",
      "Epoch 17/50\n",
      "62/62 - 1s - 11ms/step - loss: 0.0054 - val_loss: 0.0238\n",
      "Epoch 18/50\n",
      "62/62 - 1s - 11ms/step - loss: 0.0053 - val_loss: 0.0238\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "TEST 24-step ➜  RMSE = 0.159   MAE = 0.090   R² = 0.683\n",
      "Model saved → models\\chargers\\ann_chargers.keras\n"
     ]
    }
   ],
   "source": [
    "# ───────────────────────── IMPORTS ─────────────────────────\n",
    "import pathlib, math, holidays, joblib, warnings\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt               # (kept because you may plot later)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)   # optional\n",
    "\n",
    "# ───────────────────────── CONFIG ──────────────────────────\n",
    "TARGET_COL   = \"Chargers\"\n",
    "LOOK_BACK    = 168         # 3 days of hourly lags\n",
    "N_FORECAST   = 24          # predict 24 hours ahead\n",
    "EPOCHS       = 50\n",
    "BATCH_SIZE   = 256\n",
    "PATIENCE     = 8\n",
    "\n",
    "MODEL_PATH   = pathlib.Path(\"./models/chargers/ann_chargers.keras\")\n",
    "SCALER_PATH  = pathlib.Path(\"./models/chargers/charger_scaler.joblib\")\n",
    "\n",
    "START_DATE   = \"2022-09-11\"\n",
    "END_DATE     = \"2025-02-19\"\n",
    "\n",
    "# ───────────────────────── DATA LOAD ───────────────────────\n",
    "# ▸ Replace this with your real loader (CSV, SQL, etc.)\n",
    "#   The dataframe *must* have a DateTimeIndex at hourly frequency\n",
    "#   and at least one column called \"Chargers\".\n",
    "#\n",
    "\n",
    "# ─────────────────────── FEATURE ENGINEERING ───────────────\n",
    "be_holidays = set(\n",
    "    holidays.country_holidays(\"BE\", years=[2022, 2023, 2024, 2025]).keys()\n",
    ")\n",
    "\n",
    "def add_terugkomdag_feature(df):\n",
    "    terugkomdagen = [\n",
    "        datetime(2023,  9, 13), datetime(2023, 10, 26), datetime(2023, 11, 14),\n",
    "        datetime(2023, 12, 20), datetime(2024,  1, 12), datetime(2024,  2,  7),\n",
    "        datetime(2024,  3, 14), datetime(2024,  4, 16), datetime(2024,  5, 13),\n",
    "        datetime(2024,  6,  7), datetime(2024,  3, 16), datetime(2024, 10, 22),\n",
    "        datetime(2024, 11, 28), datetime(2024, 12, 18), datetime(2025,  1, 10),\n",
    "        datetime(2025,  2, 13), datetime(2025,  3, 18), datetime(2025,  4, 22),\n",
    "        datetime(2025,  5, 12), datetime(2025,  6,  6),\n",
    "    ]\n",
    "    df[\"is_terugkomdag\"] = (\n",
    "        df.index.to_series().dt.date.isin([d.date() for d in terugkomdagen]).astype(int)\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def add_cumulative_ev_phev_feature(df):\n",
    "    cumulative_data = {\n",
    "        datetime(2024,  6, 20): 35, datetime(2024,  6, 25): 36,\n",
    "        datetime(2024,  9,  5): 38, datetime(2024,  9, 12): 41,\n",
    "        datetime(2024,  9, 27): 42, datetime(2024, 10, 15): 43,\n",
    "        datetime(2024, 10, 29): 45, datetime(2024, 11,  5): 46,\n",
    "        datetime(2024, 11, 26): 47, datetime(2025,  1,  9): 48,\n",
    "        datetime(2025,  1, 23): 49, datetime(2025,  1, 28): 50,\n",
    "        datetime(2025,  2,  4): 51,\n",
    "    }\n",
    "    ev_series = (\n",
    "        pd.Series(cumulative_data)\n",
    "          .reindex(df.index.union(cumulative_data.keys()))\n",
    "          .sort_index()\n",
    "          .ffill()\n",
    "          .fillna(0)\n",
    "    )\n",
    "    df[\"cumulative_ev_phev_count\"] = ev_series.reindex(df.index).astype(int)\n",
    "    return df\n",
    "\n",
    "add_terugkomdag_feature(df)\n",
    "add_cumulative_ev_phev_feature(df)\n",
    "\n",
    "df[\"hour\"]            = df.index.hour\n",
    "df[\"day_of_week\"]     = df.index.dayofweek\n",
    "df[\"month\"]           = df.index.month\n",
    "df[\"is_weekend\"]      = (df[\"day_of_week\"] >= 5).astype(int)\n",
    "df[\"is_festive\"]      = df.index.to_series().apply(lambda d: int(d.date() in be_holidays))\n",
    "df[\"working_hour\"]    = df[\"hour\"].between(8, 18).astype(int)\n",
    "df[\"is_summer\"]       = df[\"month\"].isin([6, 7, 8]).astype(int)\n",
    "df[\"is_winter\"]       = df[\"month\"].isin([12, 1, 2]).astype(int)\n",
    "df[\"is_morning_peak\"] = df[\"hour\"].between(7,  9).astype(int)\n",
    "df[\"is_evening_peak\"] = df[\"hour\"].between(17, 20).astype(int)\n",
    "df[\"hour_sin\"]        = np.sin(2*np.pi*df[\"hour\"]/24)\n",
    "df[\"hour_cos\"]        = np.cos(2*np.pi*df[\"hour\"]/24)\n",
    "df[\"dow_sin\"]         = np.sin(2*np.pi*df[\"day_of_week\"]/7)\n",
    "df[\"dow_cos\"]         = np.cos(2*np.pi*df[\"day_of_week\"]/7)\n",
    "\n",
    "FEATURE_COLS = [c for c in df.columns if c != TARGET_COL]\n",
    "\n",
    "# ─────────────── 1️⃣  CHRONOLOGICAL SPLIT  ────────────────\n",
    "train_size = int(len(df) * 0.80)\n",
    "val_size   = int(len(df) * 0.10)\n",
    "\n",
    "df_train = df.iloc[:train_size]\n",
    "df_val   = df.iloc[train_size:train_size + val_size]\n",
    "df_test  = df.iloc[train_size + val_size:]\n",
    "\n",
    "# ─────────────── 2️⃣  FIT & SAVE SCALER  ──────────────────\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(df_train[[TARGET_COL] + FEATURE_COLS])\n",
    "SCALER_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "joblib.dump(scaler, SCALER_PATH)\n",
    "print(\"Scaler saved →\", SCALER_PATH)\n",
    "\n",
    "def scale(frame):\n",
    "    cols = [TARGET_COL] + FEATURE_COLS\n",
    "    return pd.DataFrame(\n",
    "        scaler.transform(frame[cols]),\n",
    "        columns=cols,\n",
    "        index=frame.index,\n",
    "    )\n",
    "\n",
    "df_train_s, df_val_s, df_test_s = map(scale, (df_train, df_val, df_test))\n",
    "\n",
    "# ─────────────── 3️⃣  BUILD INPUT / LABEL WINDOWS ─────────\n",
    "def make_xy(frame, look_back, horizon):\n",
    "    \"\"\"Return (X, y) where:\n",
    "       • X shape = (samples, look_back, n_features)\n",
    "       • y shape = (samples, horizon)   – multi-step forecast\n",
    "    \"\"\"\n",
    "    data = frame[[TARGET_COL] + FEATURE_COLS].values\n",
    "    X, y = [], []\n",
    "    for i in range(look_back, len(data) - horizon + 1):\n",
    "        X.append(data[i - look_back : i])\n",
    "        y.append(data[i : i + horizon, 0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X_train, y_train = make_xy(df_train_s, LOOK_BACK, N_FORECAST)\n",
    "X_val,   y_val   = make_xy(df_val_s,   LOOK_BACK, N_FORECAST)\n",
    "X_test,  y_test  = make_xy(df_test_s,  LOOK_BACK, N_FORECAST)\n",
    "\n",
    "# ─────────────── 3️⃣½  RESHAPE FOR ANN  ───────────────────\n",
    "# Flatten time dimension → feed-forward ANN expects 2-D inputs\n",
    "n_features = X_train.shape[2]\n",
    "\n",
    "X_train_f = X_train.reshape(X_train.shape[0], -1)\n",
    "X_val_f   = X_val.reshape(  X_val.shape[0],  -1)\n",
    "X_test_f  = X_test.reshape( X_test.shape[0], -1)\n",
    "\n",
    "# ─────────────── 4️⃣  DEFINE & TRAIN ANN  ────────────────\n",
    "model = Sequential([\n",
    "    InputLayer(input_shape=(LOOK_BACK * n_features,)),\n",
    "    Dense(256, activation=\"relu\"),\n",
    "    Dropout(0.3),\n",
    "    Dense(128, activation=\"relu\"),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    Dense(N_FORECAST)        # 24 output neurons – one per hour ahead\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "\n",
    "cb = EarlyStopping(\n",
    "    patience=PATIENCE,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_f, y_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(X_val_f, y_val),\n",
    "    callbacks=[cb],\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# ─────────────── 5️⃣  EVALUATE  ───────────────────────────\n",
    "y_pred = model.predict(X_test_f)\n",
    "\n",
    "rmse = math.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae  = mean_absolute_error(y_test, y_pred)\n",
    "r2   = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"TEST 24-step ➜  RMSE = {rmse:.3f}   MAE = {mae:.3f}   R² = {r2:.3f}\")\n",
    "\n",
    "# ─────────────── 6️⃣  SAVE MODEL (.keras format) ──────────\n",
    "MODEL_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "model.save(MODEL_PATH)\n",
    "print(\"Model saved →\", MODEL_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, tensorflow as tf, holidays, joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# ───────────────────────── CONFIG ──────────────────────────\n",
    "MODEL_PATH  = Path(\"./models/chargers/lstm_chargers.keras\")\n",
    "SCALER_PATH = Path(\"./models/chargers/charger_scaler.joblib\")\n",
    "CSV_PATH    = \"./3days_charging_data.csv\"\n",
    "\n",
    "DATE_COL    = \"Date\"\n",
    "TARGET_COL  = \"Chargers\"\n",
    "LOOK_BACK   = 48          # 3-day context\n",
    "FORECAST_HR = 24          # 24-step output\n",
    "HIST_HRS    = 72          # plot last 72 h\n",
    "\n",
    "# Same feature order used during training\n",
    "FEATURE_COLS = [\n",
    "    \"hour\", \"day_of_week\", \"month\", \"is_weekend\", \"is_festive\", \"working_hour\",\n",
    "    \"is_summer\", \"is_winter\", \"is_morning_peak\", \"is_evening_peak\",\n",
    "    \"hour_sin\", \"hour_cos\", \"dow_sin\", \"dow_cos\",\n",
    "    \"is_terugkomdag\", \"cumulative_ev_phev_count\"\n",
    "]\n",
    "\n",
    "# ─────────────── feature engineering helpers ───────────────\n",
    "def add_features(df_in: pd.DataFrame) -> pd.DataFrame:\n",
    "    be_holidays = set(holidays.country_holidays(\n",
    "        \"BE\", years=[2022, 2023, 2024, 2025]).keys())\n",
    "\n",
    "    terugkomdagen = {\n",
    "        datetime(2023, 9, 13), datetime(2023,10,26), datetime(2023,11,14),\n",
    "        datetime(2023,12,20), datetime(2024, 1,12), datetime(2024, 2, 7),\n",
    "        datetime(2024, 3,14), datetime(2024, 4,16), datetime(2024, 5,13),\n",
    "        datetime(2024, 6, 7), datetime(2024, 3,16), datetime(2024,10,22),\n",
    "        datetime(2024,11,28), datetime(2024,12,18), datetime(2025, 1,10),\n",
    "        datetime(2025, 2,13), datetime(2025, 3,18), datetime(2025, 4,22),\n",
    "        datetime(2025, 5,12), datetime(2025, 6, 6)\n",
    "    }\n",
    "\n",
    "    cumulative_data = {\n",
    "        datetime(2024, 6,20): 35, datetime(2024, 6,25): 36, datetime(2024, 9, 5): 38,\n",
    "        datetime(2024, 9,12): 41, datetime(2024, 9,27): 42, datetime(2024,10,15): 43,\n",
    "        datetime(2024,10,29): 45, datetime(2024,11, 5): 46, datetime(2024,11,26): 47,\n",
    "        datetime(2025, 1, 9): 48, datetime(2025, 1,23): 49, datetime(2025, 1,28): 50,\n",
    "        datetime(2025, 2, 4): 51,\n",
    "    }\n",
    "\n",
    "    df = df_in.copy()\n",
    "\n",
    "    # calendar basics\n",
    "    df[\"hour\"]        = df.index.hour\n",
    "    df[\"day_of_week\"] = df.index.dayofweek\n",
    "    df[\"month\"]       = df.index.month\n",
    "\n",
    "    # categorical flags\n",
    "    df[\"is_weekend\"]       = (df[\"day_of_week\"] >= 5).astype(int)\n",
    "    df[\"is_festive\"]       = df.index.to_series().apply(lambda d: int(d.date() in be_holidays))\n",
    "    df[\"working_hour\"]     = df[\"hour\"].between(8, 18).astype(int)\n",
    "    df[\"is_summer\"]        = df[\"month\"].isin([6,7,8]).astype(int)\n",
    "    df[\"is_winter\"]        = df[\"month\"].isin([12,1,2]).astype(int)\n",
    "    df[\"is_morning_peak\"]  = df[\"hour\"].between(7, 9).astype(int)\n",
    "    df[\"is_evening_peak\"]  = df[\"hour\"].between(17,20).astype(int)\n",
    "\n",
    "    # cyclical encodings\n",
    "    df[\"hour_sin\"] = np.sin(2*np.pi*df[\"hour\"]/24)\n",
    "    df[\"hour_cos\"] = np.cos(2*np.pi*df[\"hour\"]/24)\n",
    "    df[\"dow_sin\"]  = np.sin(2*np.pi*df[\"day_of_week\"]/7)\n",
    "    df[\"dow_cos\"]  = np.cos(2*np.pi*df[\"day_of_week\"]/7)\n",
    "\n",
    "    # business flags\n",
    "    df[\"is_terugkomdag\"] = df.index.to_series().dt.date.isin(\n",
    "        [d.date() for d in terugkomdagen]).astype(int)\n",
    "\n",
    "    ev_series = (pd.Series(cumulative_data)\n",
    "                   .reindex(df.index.union(cumulative_data.keys()))\n",
    "                   .sort_index().ffill().fillna(0))\n",
    "    df[\"cumulative_ev_phev_count\"] = ev_series.reindex(df.index).astype(int)\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_prepared(path):\n",
    "    df = pd.read_csv(path, parse_dates=[DATE_COL], index_col=DATE_COL).sort_index()\n",
    "    return add_features(df)\n",
    "\n",
    "# ────────────────────── reversible scaling ──────────────────────\n",
    "def inverse_target_direct(vec, scaler):\n",
    "    \"\"\"Method 1: direct min/max formula.\"\"\"\n",
    "    tmin, tmax = scaler.data_min_[0], scaler.data_max_[0]\n",
    "    return vec * (tmax - tmin) + tmin\n",
    "\n",
    "def inverse_target_via_params(vec, scaler):\n",
    "    \"\"\"Method 2: using scaler.min_ and scaler.scale_.\"\"\"\n",
    "    # transform: X_scaled = X * scale_ + min_\n",
    "    # invert:     X = (X_scaled - min_) / scale_\n",
    "    return (vec - scaler.min_[0]) / scaler.scale_[0]\n",
    "\n",
    "# ────────────────── forecasting & debug ──────────────────\n",
    "def forecast_next_24h(model, scaler, df):\n",
    "    # 1) build & scale the look-back window:\n",
    "    window = df[[TARGET_COL] + FEATURE_COLS].tail(LOOK_BACK).values\n",
    "    X = scaler.transform(window).reshape(1, LOOK_BACK, -1)\n",
    "    # 2) get normalized 24-step output:\n",
    "    preds_norm = model.predict(X, verbose=0)[0]\n",
    "\n",
    "    # 3a) inverse-scale by direct formula:\n",
    "    preds_direct = inverse_target_direct(preds_norm, scaler)\n",
    "    # 3b) inverse-scale by scaler params:\n",
    "    preds_params = inverse_target_via_params(preds_norm, scaler)\n",
    "\n",
    "    # 4) quick sanity print:\n",
    "    print(\"\\npreds_norm   :\", np.round(preds_norm[:5], 4))\n",
    "    print(\"direct inv   :\", np.round(preds_direct[:5], 4))\n",
    "    print(\"params inv   :\", np.round(preds_params[:5], 4))\n",
    "\n",
    "    # 5) build timestamp index\n",
    "    idx = pd.date_range(df.index[-1] + pd.Timedelta(hours=1),\n",
    "                        periods=FORECAST_HR, freq=\"h\")\n",
    "    # 6) return DataFrame from *one* of the methods (they match)\n",
    "    return pd.DataFrame({\"Predicted_kWh\": preds_direct}, index=idx)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model  = tf.keras.models.load_model(MODEL_PATH)\n",
    "    scaler = joblib.load(SCALER_PATH)\n",
    "\n",
    "    # debug: check column ordering matches scaler\n",
    "    print(\"Scaler expects:\", list(scaler.feature_names_in_))\n",
    "    print(\"We supply   :\", [TARGET_COL] + FEATURE_COLS)\n",
    "\n",
    "    df_hist    = load_prepared(CSV_PATH)\n",
    "    forecast_df= forecast_next_24h(model, scaler, df_hist)\n",
    "\n",
    "    # print results\n",
    "    print(\"\\nNext-day forecast (kWh):\")\n",
    "    print(forecast_df.to_string())\n",
    "\n",
    "    past = df_hist[TARGET_COL].iloc[-HIST_HRS:]\n",
    "    print(\"\\nLast 72 h actual consumption (kWh):\")\n",
    "    print(past.to_string())\n",
    "\n",
    "    # plot\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.plot(past.index, past.values, label=\"Past 72 h\")\n",
    "    plt.plot(forecast_df.index, forecast_df[\"Predicted_kWh\"], \"-o\",\n",
    "             label=\"Forecast next 24 h\")\n",
    "    plt.title(\"Charger load – history vs forecast\")\n",
    "    plt.xlabel(\"Hour\"); plt.ylabel(\"kWh\"); plt.legend(); plt.tight_layout(); plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
